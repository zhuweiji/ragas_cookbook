{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zhuwe\\OneDrive\\Desktop\\projects\\ragas_cookbook\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import dataclasses\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "import ragas\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import answer_correctness, faithfulness\n",
    "\n",
    "from agents.basic_agents import BasicAgent\n",
    "from agents.rag_agents import RagAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this notebook contains code to try to implement an agent that evaluates the rag pipeline\n",
    "\n",
    "starting with basic rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synthetic_data_generation.generate_syn_data import csv_to_list\n",
    "from config.project_paths import synthetic_data_dir\n",
    "import random\n",
    "qna_dir = list(synthetic_data_dir.glob('*.csv'))\n",
    "qnas = csv_to_list(qna_dir[0])\n",
    "qnas = random.sample(qnas, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.evaluator_agents import RAGResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_agent = RagAgent(config='stdout')\n",
    "\n",
    "results = []\n",
    "for question, answer in qnas:\n",
    "    response = rag_agent.answer_with_rag(question)\n",
    "    results.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluationAgent(RagAgent):\n",
    "    def evaluate_rag(self, rag_responses: list[RAGResponse], ground_truths: list[str]):\n",
    "        \n",
    "        \n",
    "        data = {\n",
    "            'question': [i.question for i in rag_responses],\n",
    "            'answer': [i.answer.content for i in rag_responses],\n",
    "            'contexts': [[doc.page_content for doc in response.documents] for response in rag_responses],\n",
    "            'ground_truth': ground_truths\n",
    "        }\n",
    "        \n",
    "        dataset = Dataset.from_dict(data)\n",
    "\n",
    "        score = evaluate(dataset,\n",
    "                        #  metrics=[faithfulness, answer_correctness],\n",
    "                         llm=self.llm,\n",
    "                         embeddings=self.retriever.embedding_function,\n",
    "                         )\n",
    "        return score.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_agent = EvaluationAgent(config='stdout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 10/10 [00:09<00:00,  1.09it/s]\n"
     ]
    }
   ],
   "source": [
    "eval_result = eval_agent.evaluate_rag(results, [i[1] for i in qnas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessibility signals are notifications that indicate the presence of certain markers on the current line, such as\n",
      "errors, warnings, breakpoints, folded text regions, or inline suggestions. They can be in the form of sounds or\n",
      "announcements and are used to aid visually impaired or screen reader users. The availability and configuration of these\n",
      "signals can be managed through settings like `accessibility.signals.*`. They are not related to color blindness or\n",
      "complementary colors.\n"
     ]
    }
   ],
   "source": [
    "from utilities import print_long_text\n",
    "\n",
    "print_long_text(eval_result['answer'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessibility signals indicate if the current line has certain markers such as errors, warnings, breakpoints, folded\n",
      "text regions or inline suggestions.\n"
     ]
    }
   ],
   "source": [
    "print_long_text(eval_result['ground_truth'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.project_paths import project_root\n",
    "eval_result.to_html(project_root / 'eval_test.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
